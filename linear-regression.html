<!DOCTYPE html>
<html>
<head>

<title>Simple Linear Regression</title>
<meta name="description" content="Simple Linear Regression">

<style>
h2 {color:red}
</style>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
</script>
</head>
<body>

<h1>Simple Linear Regression</h1>

<!---------------------------------->
<!---------------------------------->
<h2>Table of Contents</h2>

<ul>
<li><a href="#formulas">Formulas</a></li>
<li><a href="#relationships">Relationships among SSE, SSR, SST and s_x, s_y, s_xy</a></li>
<li><a href="#leastsquare">Simple Linear Regression in Statistics and Least Square Line in Linear Algebra</a></li>
<li><a href="#computationinr1">Simple Linear Regression in R---Syntax</a></li>
<li><a href="#computationinr2">Simple Linear Regression in R---Results</a></li>
<li><a href="#computationinr3">Computing F distribution and T distribution</a></li>
</ul>


<!---------------------------------->
<!---------------------------------->
<h2 id="formulas">Formulas</h2>

<p>The page numbers refer to Anderson's <i>Statistics for Business and Economics</i>.
</p>

<table border="1">

<tr>
<td>
\(\hat{y}=b_0+b_1 x\)
</td>
<td>
p.656, (14.3).
</td>
</tr>

<tr>
<td>
\(b_1=\frac{\sum_{i=1}^{n}(x_i-\overline{x})(y_i-\overline{y})}{\sum_{i=1}^{n}(x_i-\overline{x})^2}\) 
</td>
<td>
p.660, (14.7).
</td>
</tr>

<tr>
<td>
\(b_0=\overline{y}-b_1\overline{x}\) 
</td>
<td>
p.660, (14.6).
</td>
<td>
Note that this formula is very similar to \(\hat{y}=b_0+b_1 x\).
</td>
</tr>

<tr>
<td>
\(\text{SSE}=\sum_{i=1}^{n}(y_i-\hat{y}_i)^2\)
</td>
<td>
p.668, (14.8).
</td>
</tr>

<tr>
<td>
\(\text{SSR}=\sum_{i=1}^{n}(\hat{y}_i-\overline{y})^2\)
</td>
<td>
p.669, (14.10).
</td>
</tr>

<tr>
<td>
\(\text{SST}=\sum_{i=1}^{n}(y_i-\overline{y})^2\)
</td>
<td>
p.669, (14.9).
</td>
</tr>

<tr>
<td>
\(\text{SSE}+\text{SSR}=\text{SST}\)
</td>
<td>
p.679, (14.11).
</td>
</tr>

<tr>
<td>
\(\hat{\sigma}=\sqrt{\frac{\text{SSE}}{n-2}}\)
</td>
<td>
p.677, (14.16).
</td>
</tr>

<tr>
<td>
\(\hat{\sigma}_{b_1}=\frac{\hat{\sigma}}{\sqrt{\sum_{i=1}^{n}(x_i-\overline{x})^2}}\)
</td>
<td>
p.678, (14.18).
</td>
</tr>

<tr>
<td>
\(t=\frac{b_1-\beta_1}{\hat{\sigma}_{b_1}}\stackrel{H_0:\beta_1=0}{=}\frac{b_1}{\hat{\sigma}_{b_1}}\)
</td>
<td>
p.679, (14.19).
</td>
</tr>

<tr>
<td>
\(r^2=\frac{\text{SSR}}{\text{SST}}\)
</td>
<td>
p.671, (14.12).
</td>
</tr>

<tr>
<td>
\(f=\frac{\text{SSR}/1}{\text{SSE}/(n-2)}\)
</td>
<td>
p.680, (14.21).
</td>
</tr>

</table>

<canvas id="myCanvas" width="200" height="150" style="border:1px solid #d3d3d3;">
Your browser does not support the HTML5 canvas tag.</canvas>

<script>

const canvas = document.getElementById('myCanvas');
const ctx = canvas.getContext('2d');

ctx.font = "20px Arial";
ctx.fillText("SSE", 105, 25);

ctx.font = "20px Arial";
ctx.fillText("SSR", 105, 90);

ctx.font = "20px Arial";
ctx.fillText("SST", 155, 35);

ctx.moveTo(0, 150);
ctx.lineTo(200, 0);
ctx.stroke();

ctx.moveTo(150, 0);
ctx.lineTo(150, 150);
ctx.stroke();

ctx.moveTo(0, 120);
ctx.lineTo(200, 120);
ctx.stroke();
 
</script>


<table border="1">

<tr>
<td>
\(s_x=\sqrt{\frac{\sum(x_i-\bar{x})^2}{n-1}}\)
</td>
<td>
(3.8), (3.9).
</td>
</tr>

<tr>
<td>
\(s_y=\sqrt{\frac{\sum(y_i-\bar{y})^2}{n-1}}\)
</td>
<td>
(3.8), (3.9).
</td>
</tr>

<tr>
<td>
\(s_{xy}=\frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{n-1}\)
</td>
<td>
(3.13).
</td>
</tr>

<tr>
<td>
\(r_{xy}=\frac{s_{xy}}{s_x s_y}\)
</td>
<td>
(3.15).
</td>
</tr>

</table>


<!--
\(1-r^2=\frac{\text{SST}-\text{SSR}}{\text{SST}}=\frac{\text{SSE}}{\text{SST}}\)
Therefore, we can obtain \(\text{SSE}, \text{SSR}\) and \(\text{SST}\) by knowing \(\hat{\sigma}, 1-r^2\) and \(\text{SSE}+\text{SSR}=\text{SST}\)</font>
-->




<!---------------------------------->
<!---------------------------------->
<h2 id="relationships">Relationships among SSE, SSR, SST and \(s_x, s_y, s_{xy}\)</h2>


<img width="50%" src="img/linear_regression.jpg">

<p>\(\hat{\sigma}, \hat{\sigma}_{b_1}\) 沒列入。\(\text{SSE}=(n-1)\left(\frac{s_x^2 s_y^2-s_{xy}^2}{s_x^2}\right)\) 也沒列入，但不需要。
</p>

<!---------------------------------->
<!---------------------------------->
<h2 id="leastsquare">Simple Linear Regression in Statistics and Least Square Line in Linear Algebra</h2>

<p>雖然<strong>統計學中的迴歸直線</strong>跟<strong>線性代數中的最小平方直線</strong>兩者的公式看起來不一樣，但在這裡證明其實是相同的。
</p>

<p>

\[
\begin{array}{rcl}
A &=& \begin{bmatrix}x_1&1\\x_2&1\\\vdots&\vdots\\x_n&1\\\end{bmatrix} \\
A^t A &=& \begin{bmatrix}x_1&x_2&\cdots&x_n\\1&1&\cdots&1\end{bmatrix}\begin{bmatrix}x_1&1\\x_2&1\\\vdots&\vdots\\x_n&1\end{bmatrix}=\begin{bmatrix}\sum x_i^2&\sum x_i\\\sum x_i&n\end{bmatrix} \\
(A^t A)^{-1} &=& \frac{1}{n\sum x_i^2-(\sum x_i)^2}\begin{bmatrix}n&-\sum x_i\\-\sum x_i&\sum x_i^2\end{bmatrix} \\
(A^t A)^{-1}A^t
&=& \frac{1}{n\sum x_i^2-(\sum x_i)^2}\begin{bmatrix}n&-\sum x_i\\-\sum x_i&\sum x_i^2\end{bmatrix}\begin{bmatrix}x_1&x_2&\cdots&x_n\\1&1&\cdots&1\end{bmatrix} \\
&=& \frac{1}{n\sum x_i^2-(\sum x_i)^2}\begin{bmatrix}nx_1-\sum x_i&nx_2-\sum x_i&\cdots&nx_n-\sum x_i\\-x_1\sum x_i+\sum x_i^2&-x_2\sum x_i+\sum x_i^2&\cdots & -x_n\sum x_i+\sum x_i^2\end{bmatrix} \\
&=& \frac{1}{n\sum x_i^2-n^2 \bar{x}^2}\begin{bmatrix}nx_1-n\bar{x}&nx_2-n\bar{x}&\cdots&nx_n-n\bar{x}\\-x_1n\bar{x}+n\frac{\sum x_i^2}{n}&-x_2n\bar{x}+n\frac{\sum x_i^2}{n}&\cdots & -x_nn\bar{x}+n\frac{\sum x_i^2}{n}\end{bmatrix} \\
&=& \frac{1}{\sum x_i^2-n \bar{x}^2}\begin{bmatrix}x_1-\bar{x}&x_2-\bar{x}&\cdots&x_n-\bar{x}\\-x_1\bar{x}+\frac{\sum x_i^2}{n}&-x_2\bar{x}+\frac{\sum x_i^2}{n}&\cdots & -x_n\bar{x}+\frac{\sum x_i^2}{n}\end{bmatrix} \\
(A^t A)^{-1}A^t \mathbf{y}
&=& \frac{1}{\sum x_i^2-n \bar{x}^2}\begin{bmatrix}x_1-\bar{x}&x_2-\bar{x}&\cdots&x_n-\bar{x}\\-x_1\bar{x}+\frac{\sum x_i^2}{n}&-x_2\bar{x}+\frac{\sum x_i^2}{n}&\cdots & -x_n\bar{x}+\frac{\sum x_i^2}{n}\end{bmatrix}\begin{bmatrix}y_1\\y_2\\\vdots\\y_n\end{bmatrix} \\
&=& \frac{1}{\sum x_i^2-n \bar{x}^2}\begin{bmatrix}\sum(x_i-\bar{x})y_i\\\sum\left(-x_i\bar{x}+\frac{\sum x_i^2}{n}\right)y_i\end{bmatrix}
\end{array}
\]

Let us see the first component. Note that
\[
\sum(x_i-\bar{x})^2
=\sum x_i^2-2\sum x_i \bar{x}+\sum \bar{x}^2
=\sum x_i^2-2n\bar{x}^2+n\bar{x}^2
=\sum x_i^2-n\bar{x}^2
\]
and
\[
\sum(x_i-\bar{x})(y_i-\bar{y})
=\sum(x_i-\bar{x})y_i-\sum(x_i-\bar{x}\bar{y}
=\sum(x_i-\bar{x})y_i.
\]
So the first component is
\[
b_1
=\frac{\sum(x_i-\bar{x})y_i}{\sum x_i^2-n \bar{x}^2}
=\frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sum(x_i-\bar{x})^2}.
\]

The second component is
\[
\frac{\sum\left(-x_i\bar{x}+\frac{\sum x_i^2}{n}\right)y_i}{\sum x_i^2-n \bar{x}^2}
=\frac{\bar{y}\sum x_i^2-\bar{x}\sum x_i y_i}{\sum x_i^2-n \bar{x}^2}.
\]
We verify that \(b_0\) equals the second component.
\[
\begin{array}{rcl}
b_0=\bar{y}-b_1\bar{x}
&=& \bar{y}-\frac{\sum(x_i-\bar{x})y_i}{\sum x_i^2-n \bar{x}^2}\bar{x} \\
&=& \frac{\bar{y}(\sum x_i^2-n\bar{x}^2)-\sum(x_i-\bar{x})y_i\bar{x}}{\sum x_i^2-n \bar{x}^2} \\
&=& \frac{\bar{y}\sum x_i^2-n\bar{x}^2\bar{y}-\bar{x}\sum x_i y_i+\bar{x}^2 n\bar{y}}{\sum x_i^2-n \bar{x}^2} \\
&=& \frac{\bar{y}\sum x_i^2-\bar{x}\sum x_i y_i}{\sum x_i^2-n \bar{x}^2}
\end{array}
\]

</p>

<!---------------------------------->
<!---------------------------------->
<h2 id="computationinr1">Simple Linear Regression in R---Syntax</h2>

<pre>
x=c(x, ...)
y=c(y, ...)
model=lm(y~x)
summary(model)
</pre>

<p>更多模型的指令參考<a href="https://people.montefiore.uliege.be/kvansteen/GBIO0009-1/ac20092010/Class8/Using%20R%20for%20linear%20regression.pdf">這裡</a>，備份如下</p>


<table border="1">
<tr><th>Syntax</th><th>Model</th></tr>
<tr><td>y~x</td><td>\(y=\beta_0+\beta_1 x\)</td></tr>
<tr><td>y~x+I(x^2)</td><td>\(y=\beta_0+\beta_1 x+\beta_2 x^2\)</td></tr>
<tr><td>y~x1+x2</td><td>\(y=\beta_0+\beta_1 x_1+\beta_2 x_2\)</td></tr>
<tr><td>y~x1*x2</td><td>\(y=\beta_0+\beta_1 x_1+\beta_2 x_2+\beta_3 x_1 x_2\)</td></tr>
</table>


<!---------------------------------->
<!---------------------------------->
<h2 id="computationinr2">Simple Linear Regression in R---Results</h2>


<table border="1">
<tr><td>Coefficients:</td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td></td><td>Estimate</td><td>Std. Error</td><td>t value</td><td>Pr(&gt;|t|)</td><td></td></tr>
<tr><td>(Intercept)</td><td><font color="blue">\(b_0=\overline{y}-b_1\overline{x}\)</font></td><td></td><td></td><td></td><td>***</td></tr>
<tr><td>x</td><td><font color="blue">\(b_1=\frac{\sum_{i=1}^{n}(x_i-\overline{x})(y_i-\overline{y})}{\sum_{i=1}^{n}(x_i-\overline{x})^2}\)</font></td><td><font color="blue">\(\hat{\sigma}_{b_1}=\frac{\hat{\sigma}}{\sqrt{\sum_{i=1}^{n}(x_i-\overline{x})^2}}\)</font></td><td><font color="blue">\(t=\frac{b_1}{\hat{\sigma}_{b_1}}\)</font></td><td><font color="blue">\(p\)-value associated with \(t=2(1-T(t))\)</font></td><td>***</td></tr>
</table>

<p>
---<br>
Signif. codes: <font color="blue">解釋上面的***</font><br>
Residual standard error: <font color="blue">\(\hat{\sigma}=\sqrt{\frac{\text{SSE}}{n-2}}\)</font> on <font color="blue">\(n-2\)</font> degree of freedom<br>
Multiple R-squared: <font color="blue">\(r^2=\frac{\text{SSR}}{\text{SST}}\)</font>, Adjusted R-squared:<br>
F-statistic: <font color="blue">\(f=\frac{\text{SSR}/1}{\text{SSE}/(n-2)}\)</font>, p-value: <font color="blue">\(p\)-value associated with \(f=1-F(f)\)</font>
</p>

<p>The \(p\)-values associated with \(t\) is \(2(1-T(t))\), where \(T\) is the cumulative distribution function of \(t(n-1)\).
</p>

<p>The \(p\)-values associated with \(f\) is \(1-F(f)\), where \(F\) is the cumulative distribution function of \(F(1, n-2)\).
</p>

<!---------------------------------->
<!---------------------------------->
<h2 id="computationinr3">Computing F distribution and T distribution</h2>

<p>可以利用<a href="https://www.wolframalpha.com/">Wolfram Alpha</a>輸入下面指令。</p>

<pre>
CDF[FRatioDistribution[n, m], x]
CDF[StudentTDistribution[n], x]
</pre>







<!--
\begin{tikzpicture}

\draw[thick] (-2,2) -- (-2,7) -- (1,4.5) -- cycle;
\draw[thick] (-2,7) -- (-5,4.5) -- (-2,2) -- cycle;

\draw[thick] (1,-4) -- (-5,-4) -- (-2,-7.5) -- cycle;
\draw[thick] (-5,-4) -- (-4,-2) -- (0,-2) -- (1,-4) -- cycle;

\path[-] (1.5,4.5) edge [bend left, thick] (0.5,-1.5);
\path[-] (-5.5,4.5) edge [bend right, thick] (-4.5,-1.5);
\path[-] (-1.5,1.5) edge [bend left, thick] (1.5,-3.5);
\path[-] (-2.5,1.5) edge [bend right, thick] (-5.5,-3.5);

\fill (0.5,-2) circle (0pt) node[above] {$r_{xy}$};
\fill (2.5,2.5) circle (0pt) node[above] {$r_{xy}=(\text{sign of }b_1)\sqrt{r^2}$};
\fill (-2,-3.5) circle (0pt) node[above] {$r_{xy}=\frac{s_{xy}}{s_x s_y}$};

\fill (-2,-5.5) circle (0pt) node[above] {$b_1=\frac{s_{xy}}{s_x^2}$};
\fill (-2,-8) circle (0pt) node[above] {$b_1$};
\fill (1.5,-4) circle (0pt) node[above] {$s_{xy}$};
\fill (-5.5,-4) circle (0pt) node[above] {$s_x$};
\fill (-2,1.5) circle (0pt) node[above] {$\text{SSR}$};
\fill (-2,-1) circle (0pt) node[above] {$\text{SSR}=\frac{(n-1)s_{xy}^2}{s_x^2}$};

\fill (-2,7) circle (0pt) node[above] {$\text{SSE}$};
\fill (-5.5,4.5) circle (0pt) node[above] {$\text{SST}$};
\fill (-3.5,4) circle (0pt) node[above] {$\text{SSE}+\text{SSR}=\text{SST}$};
\fill (1.5,4.5) circle (0pt) node[above] {$r^2$};
\fill (-0.5,4) circle (0pt) node[above] {$r^2=\frac{\text{SSR}}{\text{SSE}+\text{SSR}}$};
\fill (-4.5,-2) circle (0pt) node[above] {$s_y$};
\fill (-6.5,2.5) circle (0pt) node[above] {$\text{SST}=(n-1)s_y^2$};

\end{tikzpicture}
-->




</body>
</html>

